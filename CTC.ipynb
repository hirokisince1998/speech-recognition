{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTCを用いた可変長音素認識\n",
    "\n",
    "これまでの検討では、訓練用データには時間情報付きの音素ラベルが与えられていることが前提でした。しかし、ほとんどの音声データベースには時間情報がなく、発話内容しか与えられていません。これは、音素の時間情報を同定する作業が非常に高コストだからです。\n",
    "\n",
    "このため、ニューラルネットを用いた音声認識は、これまでは学習時にHMM(隠れマルコフモデル)を用いた従来の音声認識を援用し、はじめに各音素の区間を音声認識によって推定する必要がありました。\n",
    "\n",
    "これに対し、近年ニューラルネットだけで音声認識を可能とする枠組がいくつか提案されています。CTC (Connectionist Temporal Classification) は、そのようなアルゴリズムの1つです。\n",
    "\n",
    "CTC は、基本的には LSTM を用いたフレームごとの音素認識に過ぎません。しかし、損失関数が異なります。CTC では、縮約すると正解音素列と一致するような全ての音素列の確率の和をネットワークの出力の「望ましさ」と考え、その対数にマイナスを付けた関数を損失関数とします。例えば、/h a i/という音素列と一致するような長さ5の音素列を全て挙げると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, cycle\n",
    "import numpy as np\n",
    "\n",
    "def expandstr(str, seqlen):\n",
    "    l = []\n",
    "    for expdstrlen in range(len(str), seqlen+1):\n",
    "        combos = combinations(range(1, expdstrlen), len(str)-1)\n",
    "        for sp in combos:\n",
    "            tmp = np.array(sp)\n",
    "            clens = np.append(tmp,expdstrlen) - np.insert(tmp,0,0)\n",
    "            bstr = \"\".join([c * clens[i] for i, c in enumerate(str)])\n",
    "            bcombos = combinations_with_replacement(range(0,expdstrlen+1), seqlen-expdstrlen)\n",
    "            # print('blank positions: {}'.format([bcombo for bcombo in bcombos]))\n",
    "            for bcombo in bcombos:\n",
    "                xstr = \"\"\n",
    "                for i in range(len(bstr)+1):\n",
    "                    xstr += '_' * bcombo.count(i)\n",
    "                    if i < len(bstr):\n",
    "                        xstr += bstr[i]\n",
    "                l.append(xstr)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__hai',\n",
       " '_h_ai',\n",
       " '_ha_i',\n",
       " '_hai_',\n",
       " 'h__ai',\n",
       " 'h_a_i',\n",
       " 'h_ai_',\n",
       " 'ha__i',\n",
       " 'ha_i_',\n",
       " 'hai__',\n",
       " '_haii',\n",
       " 'h_aii',\n",
       " 'ha_ii',\n",
       " 'hai_i',\n",
       " 'haii_',\n",
       " '_haai',\n",
       " 'h_aai',\n",
       " 'ha_ai',\n",
       " 'haa_i',\n",
       " 'haai_',\n",
       " '_hhai',\n",
       " 'h_hai',\n",
       " 'hh_ai',\n",
       " 'hha_i',\n",
       " 'hhai_',\n",
       " 'haiii',\n",
       " 'haaii',\n",
       " 'haaai',\n",
       " 'hhaii',\n",
       " 'hhaai',\n",
       " 'hhhai']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expandstr('hai',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "bcombo=(0,0)\n",
    "print(bcombo.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations(range(1, 5), 3-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (3, 3)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations_with_replacement(range(0,4),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となります。ただし _ はどの音素でもない記号で、ブランクと呼びます。\n",
    "\n",
    "以下、ネットワークの定義はLSTMの時と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/hiroki/conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "class RNN(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_lstm_layers=1, n_mid_units=100, n_out=41, dropout=0.2):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # パラメータを持つ層の登録\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_mid_units)\n",
    "            self.l2 = L.NStepBiLSTM(n_lstm_layers, n_mid_units, n_mid_units, dropout)\n",
    "            self.l3 = L.Linear(n_mid_units * 2, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # データを受け取った際のforward計算を書く\n",
    "        numframes = [X.shape[0] for X in x]\n",
    "        split_point = np.cumsum(numframes)[:-1]\n",
    "        x1 = F.concat(x, axis=0)\n",
    "        h1 = F.relu(self.l1(x1))\n",
    "        h1 = F.split_axis(h1, split_point, axis=0)\n",
    "        hy, cy, ys = self.l2(None, None, h1)\n",
    "        h2 = F.concat(ys, axis=0)\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.dataset import to_device\n",
    "from chainer.dataset import concat_examples\n",
    "import numpy as np\n",
    "\n",
    "def converter(batch, device):\n",
    "    # alternative to chainer.dataset.concat_examples\n",
    "    \n",
    "    Xs = [to_device(device, X) for X, _, __ in batch]\n",
    "    ts = [to_device(device, t) for _, t, __ in batch]\n",
    "\n",
    "    lab_batch = [lab.astype(np.int32) for _, __, lab in batch]\n",
    "    labs = concat_examples(lab_batch, device, padding=0)\n",
    "    \n",
    "    return Xs, ts, labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数\n",
    "\n",
    "CTCの損失関数は、`connectionist_temporal_classification`関数で計算できます。この関数は、これまでのようにフレームごとでなく発話全体に対して計算されます。各フレームの正解音素ラベル `t` を必要とせず、発話全体の音素ラベル列 `lab` さえあればよい点が重要なポイントです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chainer.backends import cuda\n",
    "\n",
    "def calculate_loss(model, batch, blank_symbol, gpu_id=0, train_mode=True):\n",
    "    numframes = [X.shape[0] for (X, t, lab) in batch]\n",
    "    \n",
    "    # lab を行列に変形\n",
    "    label_length = xp.array([len(lab) for (X, _t, lab) in batch],dtype=np.int32)\n",
    "    Xs, _, labs = converter(batch, gpu_id) # アラインメント済ラベルは使わない\n",
    "\n",
    "    with chainer.using_config('train', train_mode), \\\n",
    "         chainer.using_config('enable_backprop', train_mode):\n",
    "        ys = net(Xs)\n",
    "    \n",
    "    # 発話ごとに分割\n",
    "    split_point = np.cumsum(numframes)[:-1]\n",
    "    y4utt = F.split_axis(ys, split_point, axis=0)\n",
    "    input_length = xp.array(numframes, dtype=np.int32)\n",
    "    \n",
    "    # 第iフレームの確率行列(B,V)となるよう整形\n",
    "    y4utt = F.pad_sequence(y4utt)\n",
    "    y4frame = F.stack(y4utt, axis=1)\n",
    "    x = [xi for xi in y4frame]\n",
    "    \n",
    "    # ロスの計算\n",
    "    loss = F.connectionist_temporal_classification(x, labs, blank_symbol, input_length, label_length)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import chainer\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if gpu_id >= 0:\n",
    "        chainer.cuda.cupy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "with open('phones') as f:\n",
    "    phones = f.read().splitlines()\n",
    "le = LabelEncoder()\n",
    "le.fit(phones)\n",
    "blank_symbol = np.asscalar(le.transform(['_'])[0])\n",
    "nsymbol = len(phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:01 train_loss:541.2222 val_loss:401.2349\n",
      "epoch:02 train_loss:470.5593 val_loss:428.6360\n",
      "epoch:03 train_loss:427.5804 val_loss:344.4825\n",
      "epoch:04 train_loss:421.0086 val_loss:328.5212\n",
      "epoch:05 train_loss:407.4021 val_loss:335.0801\n",
      "epoch:06 train_loss:386.1248 val_loss:335.0721\n",
      "epoch:07 train_loss:396.0114 val_loss:322.8109\n",
      "epoch:08 train_loss:404.2401 val_loss:316.6742\n",
      "epoch:09 train_loss:399.6852 val_loss:312.7868\n",
      "epoch:10 train_loss:383.7752 val_loss:311.9551\n",
      "epoch:11 train_loss:356.5416 val_loss:308.7933\n",
      "epoch:12 train_loss:370.9811 val_loss:307.4981\n",
      "epoch:13 train_loss:336.1074 val_loss:304.7755\n",
      "epoch:14 train_loss:356.0455 val_loss:299.3780\n",
      "epoch:15 train_loss:366.9304 val_loss:297.7372\n",
      "epoch:16 train_loss:351.1081 val_loss:295.9219\n",
      "epoch:17 train_loss:333.5387 val_loss:298.4402\n",
      "epoch:18 train_loss:343.1516 val_loss:286.4994\n",
      "epoch:19 train_loss:327.2886 val_loss:286.1173\n",
      "epoch:20 train_loss:345.2128 val_loss:287.5588\n",
      "epoch:21 train_loss:354.4489 val_loss:274.3036\n",
      "epoch:22 train_loss:319.9510 val_loss:277.3371\n",
      "epoch:23 train_loss:309.3582 val_loss:278.3781\n",
      "epoch:24 train_loss:286.2014 val_loss:266.2406\n",
      "epoch:25 train_loss:286.0340 val_loss:256.2201\n",
      "epoch:26 train_loss:278.5067 val_loss:278.8270\n",
      "epoch:27 train_loss:286.7651 val_loss:256.9334\n",
      "epoch:28 train_loss:268.8203 val_loss:265.8394\n",
      "epoch:29 train_loss:256.2405 val_loss:229.3301\n",
      "epoch:30 train_loss:287.0712 val_loss:226.2906\n",
      "epoch:31 train_loss:258.2552 val_loss:243.5426\n",
      "epoch:32 train_loss:259.4453 val_loss:234.8174\n",
      "epoch:33 train_loss:258.8685 val_loss:237.6069\n",
      "epoch:34 train_loss:262.9168 val_loss:200.8982\n",
      "epoch:35 train_loss:204.0286 val_loss:137.8576\n",
      "epoch:36 train_loss:198.5556 val_loss:134.2487\n",
      "epoch:37 train_loss:189.7621 val_loss:133.7734\n",
      "epoch:38 train_loss:192.6959 val_loss:132.7796\n",
      "epoch:39 train_loss:191.4657 val_loss:130.8214\n",
      "epoch:40 train_loss:180.7628 val_loss:128.9111\n",
      "epoch:41 train_loss:185.0495 val_loss:126.7797\n",
      "epoch:42 train_loss:177.0843 val_loss:125.0973\n",
      "epoch:43 train_loss:181.1438 val_loss:122.7207\n",
      "epoch:44 train_loss:180.5593 val_loss:120.3666\n",
      "epoch:45 train_loss:173.8129 val_loss:117.4622\n",
      "epoch:46 train_loss:162.8457 val_loss:114.8935\n",
      "epoch:47 train_loss:159.3460 val_loss:111.6860\n",
      "epoch:48 train_loss:156.1786 val_loss:108.9864\n",
      "epoch:49 train_loss:150.0263 val_loss:105.7554\n",
      "epoch:50 train_loss:145.8576 val_loss:103.0846\n",
      "epoch:51 train_loss:143.6073 val_loss:99.6738\n",
      "epoch:52 train_loss:143.2102 val_loss:96.9214\n",
      "epoch:53 train_loss:140.1098 val_loss:93.8108\n",
      "epoch:54 train_loss:130.7264 val_loss:91.0118\n",
      "epoch:55 train_loss:125.4203 val_loss:87.8937\n",
      "epoch:56 train_loss:120.1115 val_loss:85.5213\n",
      "epoch:57 train_loss:117.2379 val_loss:82.4739\n",
      "epoch:58 train_loss:114.2638 val_loss:80.3671\n",
      "epoch:59 train_loss:111.1456 val_loss:77.4982\n",
      "epoch:60 train_loss:104.7090 val_loss:75.3549\n",
      "epoch:61 train_loss:100.1681 val_loss:72.6214\n",
      "epoch:62 train_loss:104.8023 val_loss:70.3864\n",
      "epoch:63 train_loss:95.7434 val_loss:68.1583\n",
      "epoch:64 train_loss:98.3428 val_loss:66.2983\n",
      "epoch:65 train_loss:95.4711 val_loss:64.2329\n",
      "epoch:66 train_loss:84.9364 val_loss:62.3781\n",
      "epoch:67 train_loss:83.9439 val_loss:60.6310\n",
      "epoch:68 train_loss:80.4429 val_loss:58.9941\n",
      "epoch:69 train_loss:84.3368 val_loss:57.4262\n",
      "epoch:70 train_loss:77.4023 val_loss:55.5428\n",
      "epoch:71 train_loss:75.6833 val_loss:53.8885\n",
      "epoch:72 train_loss:72.8360 val_loss:52.7405\n",
      "epoch:73 train_loss:71.6482 val_loss:50.8427\n",
      "epoch:74 train_loss:69.9184 val_loss:49.3458\n",
      "epoch:75 train_loss:70.0314 val_loss:47.8657\n",
      "epoch:76 train_loss:66.0022 val_loss:46.6803\n",
      "epoch:77 train_loss:66.5091 val_loss:45.5956\n",
      "epoch:78 train_loss:63.4827 val_loss:44.2017\n",
      "epoch:79 train_loss:59.0400 val_loss:42.4070\n",
      "epoch:80 train_loss:58.7525 val_loss:41.8008\n",
      "epoch:81 train_loss:52.9696 val_loss:40.5457\n",
      "epoch:82 train_loss:56.5738 val_loss:39.6653\n",
      "epoch:83 train_loss:51.3207 val_loss:38.4625\n",
      "epoch:84 train_loss:47.4421 val_loss:37.7591\n",
      "epoch:85 train_loss:50.4950 val_loss:36.7261\n",
      "epoch:86 train_loss:46.9736 val_loss:35.6274\n",
      "epoch:87 train_loss:45.9854 val_loss:35.3466\n",
      "epoch:88 train_loss:46.5631 val_loss:34.2205\n",
      "epoch:89 train_loss:44.9775 val_loss:33.4770\n",
      "epoch:90 train_loss:43.5498 val_loss:32.5848\n",
      "epoch:91 train_loss:41.0929 val_loss:31.7609\n",
      "epoch:92 train_loss:41.9291 val_loss:31.3661\n",
      "epoch:93 train_loss:38.2912 val_loss:30.7623\n",
      "epoch:94 train_loss:38.1810 val_loss:30.2500\n",
      "epoch:95 train_loss:37.6405 val_loss:29.6292\n",
      "epoch:96 train_loss:35.8919 val_loss:28.7568\n",
      "epoch:97 train_loss:35.6107 val_loss:28.2853\n",
      "epoch:98 train_loss:34.0894 val_loss:27.7947\n",
      "epoch:99 train_loss:33.5981 val_loss:27.2146\n",
      "epoch:100 train_loss:33.2651 val_loss:27.0049\n",
      "epoch:101 train_loss:31.4261 val_loss:26.1413\n",
      "epoch:102 train_loss:32.5528 val_loss:26.7162\n",
      "epoch:103 train_loss:32.4428 val_loss:25.8446\n",
      "epoch:104 train_loss:28.7374 val_loss:24.9895\n",
      "epoch:105 train_loss:28.5935 val_loss:25.1200\n",
      "epoch:106 train_loss:29.0761 val_loss:24.1070\n",
      "epoch:107 train_loss:29.0126 val_loss:23.7782\n",
      "epoch:108 train_loss:28.1229 val_loss:23.5268\n",
      "epoch:109 train_loss:26.6552 val_loss:22.8671\n",
      "epoch:110 train_loss:25.1929 val_loss:22.6573\n",
      "epoch:111 train_loss:25.0267 val_loss:22.5711\n",
      "epoch:112 train_loss:25.0664 val_loss:22.2143\n",
      "epoch:113 train_loss:24.1688 val_loss:21.9405\n",
      "epoch:114 train_loss:23.7986 val_loss:21.3648\n",
      "epoch:115 train_loss:22.7244 val_loss:21.0281\n",
      "epoch:116 train_loss:22.9502 val_loss:21.1124\n",
      "epoch:117 train_loss:23.5720 val_loss:20.6595\n",
      "epoch:118 train_loss:21.1540 val_loss:20.4363\n",
      "epoch:119 train_loss:19.9519 val_loss:19.9532\n",
      "epoch:120 train_loss:19.8897 val_loss:19.6889\n",
      "epoch:121 train_loss:19.5126 val_loss:19.4863\n",
      "epoch:122 train_loss:18.8062 val_loss:19.0954\n",
      "epoch:123 train_loss:17.8043 val_loss:18.7655\n",
      "epoch:124 train_loss:17.7299 val_loss:18.6579\n",
      "epoch:125 train_loss:18.3467 val_loss:18.3850\n",
      "epoch:126 train_loss:16.6552 val_loss:18.0485\n",
      "epoch:127 train_loss:16.8012 val_loss:17.6658\n",
      "epoch:128 train_loss:16.2221 val_loss:18.3552\n",
      "epoch:129 train_loss:15.5830 val_loss:17.9641\n",
      "epoch:130 train_loss:16.1628 val_loss:17.4045\n",
      "epoch:131 train_loss:14.7924 val_loss:17.5400\n",
      "epoch:132 train_loss:14.3566 val_loss:17.1836\n",
      "epoch:133 train_loss:14.1718 val_loss:17.1622\n",
      "epoch:134 train_loss:14.0871 val_loss:16.9397\n",
      "epoch:135 train_loss:13.5932 val_loss:16.8801\n",
      "epoch:136 train_loss:13.7340 val_loss:16.8252\n",
      "epoch:137 train_loss:13.9538 val_loss:16.4005\n",
      "epoch:138 train_loss:12.4236 val_loss:16.3341\n",
      "epoch:139 train_loss:12.2103 val_loss:16.0771\n",
      "epoch:140 train_loss:11.9891 val_loss:16.2883\n",
      "epoch:141 train_loss:11.3783 val_loss:15.9368\n",
      "epoch:142 train_loss:11.5475 val_loss:15.8426\n",
      "epoch:143 train_loss:9.9002 val_loss:16.0284\n",
      "epoch:144 train_loss:11.3215 val_loss:15.6441\n",
      "epoch:145 train_loss:10.3241 val_loss:15.7143\n",
      "epoch:146 train_loss:10.3439 val_loss:15.7661\n",
      "epoch:147 train_loss:9.7394 val_loss:15.4384\n",
      "epoch:148 train_loss:9.8913 val_loss:15.9651\n",
      "epoch:149 train_loss:10.0568 val_loss:15.2243\n",
      "epoch:150 train_loss:10.0423 val_loss:15.4532\n",
      "epoch:151 train_loss:8.9400 val_loss:15.1157\n",
      "epoch:152 train_loss:9.1419 val_loss:15.1482\n",
      "epoch:153 train_loss:8.3266 val_loss:14.8960\n",
      "epoch:154 train_loss:8.5183 val_loss:15.3929\n",
      "epoch:155 train_loss:7.7732 val_loss:15.0958\n",
      "epoch:156 train_loss:8.3236 val_loss:14.8778\n",
      "epoch:157 train_loss:8.1037 val_loss:14.8149\n",
      "epoch:158 train_loss:7.7068 val_loss:14.8919\n",
      "epoch:159 train_loss:7.8582 val_loss:14.6703\n",
      "epoch:160 train_loss:7.3598 val_loss:14.9698\n",
      "epoch:161 train_loss:6.9532 val_loss:14.5815\n",
      "epoch:162 train_loss:7.2369 val_loss:14.6348\n",
      "epoch:163 train_loss:6.9370 val_loss:14.4458\n",
      "epoch:164 train_loss:6.8747 val_loss:14.5735\n",
      "epoch:165 train_loss:6.5649 val_loss:14.4576\n",
      "epoch:166 train_loss:6.5566 val_loss:14.5954\n",
      "epoch:167 train_loss:6.2662 val_loss:14.5208\n",
      "epoch:168 train_loss:6.1497 val_loss:14.5927\n",
      "epoch:169 train_loss:5.6288 val_loss:14.2435\n",
      "epoch:170 train_loss:5.7814 val_loss:14.2652\n",
      "epoch:171 train_loss:5.2560 val_loss:14.1815\n",
      "epoch:172 train_loss:5.5427 val_loss:14.3237\n",
      "epoch:173 train_loss:5.1575 val_loss:14.3667\n",
      "epoch:174 train_loss:5.1762 val_loss:14.3110\n",
      "epoch:175 train_loss:5.6743 val_loss:14.4400\n",
      "epoch:176 train_loss:4.6169 val_loss:14.0838\n",
      "epoch:177 train_loss:4.9676 val_loss:13.8677\n",
      "epoch:178 train_loss:4.5174 val_loss:14.4051\n",
      "epoch:179 train_loss:4.7669 val_loss:14.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:180 train_loss:4.1837 val_loss:13.9531\n",
      "epoch:181 train_loss:4.0463 val_loss:13.9105\n",
      "epoch:182 train_loss:3.9053 val_loss:13.8159\n",
      "epoch:183 train_loss:4.2023 val_loss:13.9348\n",
      "epoch:184 train_loss:3.5191 val_loss:13.6672\n",
      "epoch:185 train_loss:3.8324 val_loss:13.8428\n",
      "epoch:186 train_loss:4.0660 val_loss:13.7634\n",
      "epoch:187 train_loss:3.8980 val_loss:13.6361\n",
      "epoch:188 train_loss:3.8478 val_loss:14.3007\n",
      "epoch:189 train_loss:3.6572 val_loss:14.0663\n",
      "epoch:190 train_loss:3.4105 val_loss:13.4339\n",
      "epoch:191 train_loss:3.4242 val_loss:13.5659\n",
      "epoch:192 train_loss:3.6747 val_loss:13.9719\n",
      "epoch:193 train_loss:3.1519 val_loss:13.7959\n",
      "epoch:194 train_loss:3.2905 val_loss:13.7073\n",
      "epoch:195 train_loss:2.7839 val_loss:13.4870\n",
      "epoch:196 train_loss:2.8311 val_loss:14.0571\n",
      "epoch:197 train_loss:3.0772 val_loss:13.7330\n",
      "epoch:198 train_loss:2.6498 val_loss:13.7721\n",
      "epoch:199 train_loss:2.7508 val_loss:13.6288\n",
      "epoch:200 train_loss:2.6865 val_loss:13.8908\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "from chainer.backends import cuda\n",
    "from chainer.cuda import to_cpu\n",
    "from chainer.dataset import concat_examples\n",
    "\n",
    "gpu_id = 0 # CPUを用いる場合は、この値を-1にしてください\n",
    "\n",
    "batchsize = 100\n",
    "max_epoch = 200\n",
    "\n",
    "xp = np\n",
    "if gpu_id >= 0:\n",
    "    xp = chainer.cuda.cupy\n",
    "\n",
    "reset_seed(1234) # 乱数の種をセット\n",
    "\n",
    "train = np.load(\"MHT-train.npy\") # train: 450 x (framelen x 26 , framelen, maxphonenum)\n",
    "test = np.load(\"MHT-test.npy\")\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "\n",
    "# dropoutを大きくしないと、訓練データの音素列に過剰に適合するようだ\n",
    "net = RNN(n_lstm_layers=1, n_mid_units=200, n_out=nsymbol, dropout=0.4)\n",
    "\n",
    "#optimizer = optimizers.SGD(lr=0.0001).setup(net)\n",
    "optimizer = optimizers.Adam().setup(net)\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    net.to_gpu(gpu_id)\n",
    "    \n",
    "while train_iter.epoch < max_epoch:\n",
    "\n",
    "    # ---------- 学習の1イテレーション ----------\n",
    "    train_batch = train_iter.next()\n",
    "\n",
    "    loss = calculate_loss(net, train_batch, blank_symbol, gpu_id, train_mode = True)\n",
    "\n",
    "    # 勾配の計算\n",
    "    net.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # バッチ単位で古い記憶を削除し、計算コストを削減する。\n",
    "    loss.unchain_backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    optimizer.update()\n",
    "    \n",
    "    # --------------- ここまで ----------------\n",
    "\n",
    "    # 1エポック終了ごとにValidationデータに対する予測精度を測って、\n",
    "    # モデルの汎化性能が向上していることをチェックしよう\n",
    "    if train_iter.is_new_epoch:  # 1 epochが終わったら\n",
    "        # ロスの表示\n",
    "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
    "            train_iter.epoch, float(to_cpu(loss.data))), end='')\n",
    "\n",
    "        valid_losses = []\n",
    "        \n",
    "        loss_valid = calculate_loss(net, test, blank_symbol, gpu_id, train_mode=False)\n",
    "        valid_losses.append(to_cpu(loss_valid.array))\n",
    "\n",
    "        print('val_loss:{:.04f}'.format(np.mean(valid_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 音素認識結果の観察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_utterance_number = 0\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    net.to_gpu(gpu_id)\n",
    "\n",
    "Xs, _, __ = converter(test, gpu_id)\n",
    "\n",
    "# テストデータを1つ取り出します\n",
    "X_test = Xs[test_utterance_number]\n",
    "_, __, lab_test = test[test_utterance_number]\n",
    "\n",
    "with chainer.using_config('train', False), \\\n",
    "     chainer.using_config('enable_backprop', False):\n",
    "    y_test = net([X_test])\n",
    "\n",
    "# Variable形式で出てくるので中身を取り出す\n",
    "y_test = y_test.array\n",
    "\n",
    "# 結果をCPUに送る\n",
    "y_test = to_cpu(y_test)\n",
    "\n",
    "# 予測確率の最大値のインデックスを見る\n",
    "pred_label = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータの0番目 (Jセット第1文) の正解音素列は次の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/hiroki/conda/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sil', 'ch', 'i', 'i', 's', 'a', 'n', 'a', 'u', 'n', 'a', 'g', 'i',\n",
       "       'y', 'a', 'n', 'i', 'pau', 'n', 'e', 'Q', 'k', 'i', 'n', 'o', 'y',\n",
       "       'o', 'o', 'n', 'a', 'm', 'o', 'n', 'o', 'g', 'a', 'm', 'i', 'n',\n",
       "       'a', 'g', 'i', 'r', 'u', 'sil'], dtype='<U3')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これに対し、まず各フレームに対する音素認識結果を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/hiroki/conda/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['_', '_', '_', '_', '_', '_', '_', '_', 'sil', 'sil', 'sil', '_',\n",
       "       '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', 'ch', 'ch', 'ch', '_', '_', '_', '_', 'i', 'i',\n",
       "       'i', 'i', 'i', 'i', 'i', 'i', '_', '_', '_', '_', '_', '_', 's',\n",
       "       's', 's', '_', '_', 'a', 'a', 'a', '_', '_', '_', '_', 'n', 'n',\n",
       "       'n', 'a', 'a', '_', '_', '_', '_', '_', '_', '_', '_', 'u', 'u',\n",
       "       'u', '_', '_', '_', '_', '_', '_', '_', '_', 'n', 'n', 'a', 'a',\n",
       "       'a', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'g', 'g',\n",
       "       'g', '_', '_', '_', '_', '_', '_', 'i', 'i', 'i', 'i', 'i', 'y',\n",
       "       '_', 'a', 'a', 'a', 'a', '_', '_', '_', '_', '_', '_', '_', '_',\n",
       "       'n', 'n', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'i',\n",
       "       'i', 'i', '_', '_', '_', '_', '_', 'pau', 'pau', '_', '_', '_',\n",
       "       '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', 'n', 'n', 'e', 'e', 'e', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', '_', '_', 'Q', 'Q', 'Q', '_', '_', '_', '_',\n",
       "       '_', 'k', 'k', '_', '_', '_', 'i', 'i', '_', '_', '_', '_', 'n',\n",
       "       'n', '_', '_', 'o', 'o', 'o', 'o', '_', '_', '_', '_', '_', 'y',\n",
       "       '_', '_', '_', '_', 'o', 'o', 'o', '_', '_', '_', 'o', 'o', 'o',\n",
       "       'o', '_', '_', '_', 'n', 'n', 'n', 'a', 'a', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', 'm', 'm', 'm', '_', '_', 'o', 'o', 'o', '_',\n",
       "       '_', '_', 'n', 'n', '_', '_', 'o', 'o', '_', '_', '_', '_', '_',\n",
       "       'g', 'g', 'a', 'a', 'a', 'a', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', '_', 'n', '_', '_', '_', '_', '_', 'i', 'i',\n",
       "       '_', '_', '_', '_', 'n', 'n', 'a', 'a', 'a', 'a', '_', '_', '_',\n",
       "       '_', '_', '_', '_', 'N', 'N', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', 'i', 'i', '_', '_', '_', '_', 'r', 'r', 'r',\n",
       "       'u', 'u', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_',\n",
       "       '_', '_', '_', '_', 'sil', 'sil'], dtype='<U3')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多くのフレームで _ (ブランク) が出力されているのがわかります。これは、最も「自信がある」フレームに対してだけ具体的な音素が出力され、音素境界に近い曖昧な部分では何も出力していないものと解釈することができます。\n",
    "\n",
    "繰り返しですが、この結果をLSTM等と単純に比較することはできません。CTCの学習には音素の時間情報を使っていないので、こちらの方が不利だからです。\n",
    "\n",
    "出力された冗長な音素列を縮約することで、次のように最終的な音素認識結果が得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/hiroki/conda/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sil', 'ch', 'i', 's', 'a', 'n', 'a', 'u', 'n', 'a', 'g', 'i', 'y',\n",
       "       'a', 'n', 'i', 'pau', 'n', 'e', 'Q', 'k', 'i', 'n', 'o', 'y', 'o',\n",
       "       'o', 'n', 'a', 'm', 'o', 'n', 'o', 'g', 'a', 'n', 'i', 'n', 'a',\n",
       "       'N', 'i', 'r', 'u', 'sil'], dtype='<U3')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = pred_label[:-1] != pred_label[1:]\n",
    "tmp_label = pred_label[np.append(mask,True)]\n",
    "mask = tmp_label != blank_symbol\n",
    "le.inverse_transform(tmp_label[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
